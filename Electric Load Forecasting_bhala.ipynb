{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder\n",
    "\n",
    "This is a 4 layers Autoencoder(2 encoder + 2 decoder) for performing dimensionality reduction on the GEFCOM-2014 load forecasting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta, datetime\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "CUDA_ENABLED = True\n",
    "\n",
    "if CUDA_ENABLED:\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing & Staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_name):\n",
    "    data = pd.read_csv(file_name)\n",
    "    data = data.to_numpy()\n",
    "    for i in range(data.shape[0]):\n",
    "        data[i, 1] = datetime.strptime(data[i, 1], \"%m%d%Y %H:%M\").date()\n",
    "    power = data[:, 2].astype(np.float64)\n",
    "    indexes = np.isnan(power)\n",
    "    cleaned_data = data[~indexes, :]\n",
    "    return cleaned_data\n",
    "\n",
    "def embed_data(lead_time, embed_dim, from_date, to_date, data, t_idx, dt_idx):\n",
    "    start = np.where(data[:, dt_idx] == from_date)[0][0]\n",
    "    end = np.where(data[:, dt_idx] == to_date)[0][-1]\n",
    "    X, y = [], []\n",
    "    for idx in range(start, end+1):\n",
    "        xx = data[idx-(embed_dim+lead_time-1):idx-lead_time+1, 3:]\n",
    "        yy = data[idx, 2]\n",
    "        X.append(xx)\n",
    "        y.append(yy)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def get_data_between_time(data, from_date, to_date, dt_idx):\n",
    "    start = np.where(data[:, dt_idx] == from_date)[0][0]\n",
    "    end = np.where(data[:, dt_idx] == to_date)[0][-1]\n",
    "    return data[start:(end+1), :]\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    mean_out, stds_out = 0, 0\n",
    "    for i in range(2, data.shape[1]):\n",
    "        if i == 2:\n",
    "            mean_out = np.mean(data[:, i])\n",
    "            stds_out = np.std(data[:, i])\n",
    "        data[:, i] = (data[:, i] - np.mean(data[:, i]))/np.std(data[:, i])\n",
    "    return data, mean_out, stds_out\n",
    "\n",
    "def denormalize(y, mean, std):\n",
    "    return y*std + mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data('data/task_1/L1-train.csv')\n",
    "data, mean_out, stds_out = normalize(data)\n",
    "embedded_data, target = embed_data(\n",
    "    lead_time = 6,\n",
    "    embed_dim = 12,\n",
    "    from_date = date(month=2, year=2005, day=1),\n",
    "    to_date = date(month=2, year=2006, day=1),\n",
    "    data = data,\n",
    "    t_idx = 2,\n",
    "    dt_idx = 1\n",
    ")\n",
    "\n",
    "train_x = embedded_data.astype(np.float32)\n",
    "train_y = target.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantileRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers, seq_length, alpha, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.seq_length = seq_length\n",
    "        self.num_layers = num_layers\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, \n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, \n",
    "                            batch_first=True, bidirectional=False)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, 10)\n",
    "        self.fc_out = nn.Linear(10, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        c_0 = Variable(torch.zeros(\n",
    "            self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        # Propagate input through LSTM\n",
    "        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        h_out = h_out.view(batch_size*self.num_layers, self.hidden_size)\n",
    "        \n",
    "        fc1 = self.fc(h_out)\n",
    "        out = self.fc_out(fc1)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def train_model(self, trainX, trainY, lr, epochs, sample_size, verbose=True):\n",
    "        learning_rate = lr\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        losses = []\n",
    "        num_epochs = epochs\n",
    "        \n",
    "        for epoch in range(num_epochs):  \n",
    "            indices = torch.randperm(trainX.size()[0])\n",
    "            trainX, trainY = trainX[indices, :, :], trainY[indices]\n",
    "            for i in range(0, trainX.size()[0], sample_size):\n",
    "                xx = trainX[i: i + sample_size, :, :]\n",
    "                yy = trainY[i: i + sample_size]\n",
    "                outputs = self.forward(xx)\n",
    "                outputs = outputs.view(self.num_layers, self.output_size, -1)\n",
    "                optimizer.zero_grad()\n",
    "                alpha = self.alpha\n",
    "                # obtain the loss function\n",
    "                loss = self.quantile_loss(outputs[-1, :, :], yy)\n",
    "                losses.append(loss.item())\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "            if verbose:\n",
    "                print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n",
    "            \n",
    "        return losses\n",
    "    \n",
    "    def train_sgd(self, trainX, trainY, lr, epochs, sample_size):\n",
    "        learning_rate = lr\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learning_rate)\n",
    "        losses = []\n",
    "        num_epochs = epochs\n",
    "        for epoch in range(num_epochs):\n",
    "            for xx, yy in zip(trainX, trainY):\n",
    "                xx = xx.view(1, self.seq_length, self.input_size)\n",
    "                outputs = self.forward(xx)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # obtain the loss function\n",
    "                loss = self.quantile_loss(outputs, yy)\n",
    "                losses.append(loss)\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "            print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))\n",
    "        return losses\n",
    "    \n",
    "    def quantile_loss(self, output, target):\n",
    "        covered_flag = (output <= target).float()\n",
    "        uncovered_flag = (output > target).float()\n",
    "        return torch.mean((target - output)*(self.alpha)*covered_flag + (output-target)*(1-self.alpha)*uncovered_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoded_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b8e7557fe06f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mfrom_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mto_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2006\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mday\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mt_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mdt_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'encoded_data' is not defined"
     ]
    }
   ],
   "source": [
    "def quantile_loss(output, target, alpha):\n",
    "    covered_flag = (output <= target)\n",
    "    uncovered_flag = (output > target)\n",
    "    return np.mean((target - output)*(alpha)*covered_flag + (output-target)*(1-alpha)*uncovered_flag)\n",
    "\n",
    "lead_time = [6, 12]\n",
    "embed_dims = [12, 24, 36]\n",
    "quantiles = np.arange(0.05, 1.0, 0.05)\n",
    "\n",
    "for l in lead_time:\n",
    "    for e in embed_dims:\n",
    "        embedded_data, target = embed_data(\n",
    "            lead_time = l,\n",
    "            embed_dim = e,\n",
    "            from_date = date(month=2, year=2005, day=1),\n",
    "            to_date = date(month=1, year=2006, day=31),\n",
    "            data = encoded_data,\n",
    "            t_idx = 2,\n",
    "            dt_idx = 1\n",
    "        )\n",
    "\n",
    "        train_x = embedded_data.astype(np.float32)\n",
    "        train_y = target.astype(np.float32)\n",
    "\n",
    "        trainX = Variable(torch.from_numpy(train_x)).cuda()\n",
    "        trainY = Variable(torch.from_numpy(train_y)).cuda()\n",
    "        \n",
    "        embedded_data_test, target_test = embed_data(\n",
    "            lead_time = l,\n",
    "            embed_dim = e,\n",
    "            from_date = date(month=2, year=2006, day=1),\n",
    "            to_date = date(month=1, year=2007, day=31),\n",
    "            data = encoded_data,\n",
    "            t_idx = 2,\n",
    "            dt_idx = 1\n",
    "        )\n",
    "\n",
    "        test_x = embedded_data_test.astype(np.float32)\n",
    "        test_y = target_test.astype(np.float32)\n",
    "\n",
    "        testX = Variable(torch.from_numpy(test_x)).cuda()\n",
    "        testY = Variable(torch.from_numpy(test_y)).cuda()\n",
    "        crps = []\n",
    "        for q in tqdm(quantiles):\n",
    "            regressor = QuantileRegression(\n",
    "                input_size = 15,\n",
    "                hidden_size = 40,\n",
    "                output_size = 1,\n",
    "                num_layers = 1,\n",
    "                seq_length = e,\n",
    "                alpha=q\n",
    "            )\n",
    "\n",
    "            losses = regressor.train_model(\n",
    "                trainX = trainX,\n",
    "                trainY = trainY,\n",
    "                lr = 0.005,\n",
    "                epochs = 200,\n",
    "                sample_size = 50,\n",
    "                verbose = False\n",
    "            )\n",
    "            \n",
    "            regressor.eval()\n",
    "            predY = regressor(testX).data.cpu().detach().numpy()\n",
    "            predY = denormalize(predY, mean_out, stds_out)\n",
    "            testYDenorm = denormalize(test_y, mean_out, stds_out)\n",
    "            crps.append(quantile_loss(predY, testYDenorm, q))\n",
    "            print(crps[-1])\n",
    "        print(\"Error for Lead Time : \", l, \"Embed Dim: \", e, \" CRPS: \", sum(crps)/len(crps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_time = [6, 12]\n",
    "embed_dims = [12, 24, 36]\n",
    "quantiles = np.arange(0.05, 1.0, 0.05)\n",
    "\n",
    "for l in lead_time:\n",
    "    for e in embed_dims:\n",
    "        embedded_data, target = embed_data(\n",
    "            lead_time = l,\n",
    "            embed_dim = e,\n",
    "            from_date = date(month=2, year=2005, day=1),\n",
    "            to_date = date(month=1, year=2006, day=31),\n",
    "            data = data,\n",
    "            t_idx = 2,\n",
    "            dt_idx = 1\n",
    "        )\n",
    "\n",
    "        train_x = embedded_data.astype(np.float32)\n",
    "        train_y = target.astype(np.float32)\n",
    "\n",
    "        trainX = Variable(torch.from_numpy(train_x)).cuda()\n",
    "        trainY = Variable(torch.from_numpy(train_y)).cuda()\n",
    "        \n",
    "        embedded_data_test, target_test = embed_data(\n",
    "            lead_time = l,\n",
    "            embed_dim = e,\n",
    "            from_date = date(month=2, year=2006, day=1),\n",
    "            to_date = date(month=1, year=2007, day=31),\n",
    "            data = data,\n",
    "            t_idx = 2,\n",
    "            dt_idx = 1\n",
    "        )\n",
    "\n",
    "        test_x = embedded_data_test.astype(np.float32)\n",
    "        test_y = target_test.astype(np.float32)\n",
    "\n",
    "        testX = Variable(torch.from_numpy(test_x)).cuda()\n",
    "        testY = Variable(torch.from_numpy(test_y)).cuda()\n",
    "        crps = []\n",
    "        for q in tqdm(quantiles):\n",
    "            regressor = QuantileRegression(\n",
    "                input_size = 25,\n",
    "                hidden_size = 40,\n",
    "                output_size = 1,\n",
    "                num_layers = 1,\n",
    "                seq_length = e,\n",
    "                alpha=q\n",
    "            )\n",
    "\n",
    "            losses = regressor.train_model(\n",
    "                trainX = trainX,\n",
    "                trainY = trainY,\n",
    "                lr = 0.005,\n",
    "                epochs = 200,\n",
    "                sample_size = 50,\n",
    "                verbose = False\n",
    "            )\n",
    "            \n",
    "            regressor.eval()\n",
    "            test_predict = regressor(testX)\n",
    "            crps.append(regressor.quantile_loss(test_predict, testY).item())\n",
    "        print(\"Error for Lead Time : \", l, \"Embed Dim: \", e, \" RMSE: \", sum(crps)/len(crps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9f63a284cdde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataY_plot\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrainY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataY_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'regressor' is not defined"
     ]
    }
   ],
   "source": [
    "regressor.eval()\n",
    "train_predict = regressor(trainX)\n",
    "data_predict = train_predict.data.cpu().detach().numpy()\n",
    "dataY_plot =  trainY.data.cpu().detach().numpy()\n",
    "print(data_predict.shape, dataY_plot.shape)\n",
    "\n",
    "figure(num=None, figsize=(20, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "layers  = 1\n",
    "from_here = int(data_predict.shape[0] / layers)\n",
    "plt.plot(dataY_plot[:200])\n",
    "plt.plot(data_predict[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Check post Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_reduced, train_target_reduced = embed_data(\n",
    "    lead_time = 6,\n",
    "    embed_dim = 12,\n",
    "    from_date = date(month=2, year=2006, day=1),\n",
    "    to_date = date(month=4, year=2006, day=30),\n",
    "    data = encoded_data,\n",
    "    t_idx = 2,\n",
    "    dt_idx = 1\n",
    ")\n",
    "\n",
    "\n",
    "regressor_reduced_dim = QuantileRegression(\n",
    "    input_size=15,\n",
    "    output_size=1,\n",
    "    hidden_size=40,\n",
    "    num_layers=1,\n",
    "    seq_length=12,\n",
    "    alpha=0.9\n",
    ")\n",
    "\n",
    "train_x = train_data_reduced.astype(np.float32)\n",
    "train_y = train_target_reduced.astype(np.float32)\n",
    "\n",
    "trainX = Variable(torch.from_numpy(train_x))\n",
    "trainY = Variable(torch.from_numpy(train_y))\n",
    "\n",
    "losses = regressor_reduced_dim.train_model(\n",
    "    trainX = trainX,\n",
    "    trainY = trainY,\n",
    "    lr = 0.005,\n",
    "    epochs = 100,\n",
    "    sample_size = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_original, train_target_original = embed_data(\n",
    "    lead_time = 6,\n",
    "    embed_dim = 12,\n",
    "    from_date = date(month=2, year=2006, day=1),\n",
    "    to_date = date(month=4, year=2006, day=30),\n",
    "    data = data,\n",
    "    t_idx = 2,\n",
    "    dt_idx = 1\n",
    ")\n",
    "\n",
    "regressor_original_dim = QuantileRegression(\n",
    "    input_size=25,\n",
    "    output_size=1,\n",
    "    hidden_size=40,\n",
    "    num_layers=1,\n",
    "    seq_length=12,\n",
    "    alpha = 0.9\n",
    ")\n",
    "\n",
    "train_x = train_data_original.astype(np.float32)\n",
    "train_y = train_target_original.astype(np.float32)\n",
    "\n",
    "trainX = Variable(torch.from_numpy(train_x))\n",
    "trainY = Variable(torch.from_numpy(train_y))\n",
    "\n",
    "losses = regressor_original_dim.train_model(\n",
    "    trainX = trainX,\n",
    "    trainY = trainY,\n",
    "    lr = 0.005,\n",
    "    epochs = 100,\n",
    "    sample_size = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_data_test, target_test = embed_data(\n",
    "    lead_time = 6,\n",
    "    embed_dim = 12,\n",
    "    from_date = date(month=5, year=2006, day=1),\n",
    "    to_date = date(month=6, year=2006, day=30),\n",
    "    data = data,\n",
    "    t_idx = 2,\n",
    "    dt_idx = 1\n",
    ")\n",
    "test_x_original = embedded_data_test.astype(np.float32)\n",
    "test_y_original = target_test.astype(np.float32)\n",
    "\n",
    "testXOriginal = Variable(torch.from_numpy(test_x_original))\n",
    "\n",
    "embedded_encoded_data_test, target_test = embed_data(\n",
    "    lead_time = 6,\n",
    "    embed_dim = 12,\n",
    "    from_date = date(month=5, year=2006, day=1),\n",
    "    to_date = date(month=6, year=2006, day=30),\n",
    "    data = encoded_data,\n",
    "    t_idx = 2,\n",
    "    dt_idx = 1\n",
    ")\n",
    "\n",
    "test_x_reduced = embedded_encoded_data_test.astype(np.float32)\n",
    "test_y_reduced = target_test.astype(np.float32)\n",
    "\n",
    "testXReduced = Variable(torch.from_numpy(test_x_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_original_dim.eval()\n",
    "testYOriginalPredict = regressor_original_dim(testXOriginal)\n",
    "test_pred_original = testYOriginalPredict.data.numpy()\n",
    "\n",
    "regressor_reduced_dim.eval()\n",
    "testYReducedPredict = regressor_reduced_dim(testXReduced)\n",
    "test_pred_reduced = testYReducedPredict.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(output, target, alpha):\n",
    "    covered_flag = (output <= target).astype(np.float32)\n",
    "    uncovered_flag = (output > target).astype(np.float32)\n",
    "    return np.mean((target - output)*(alpha)*covered_flag + (output-target)*(1-alpha)*uncovered_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(quantile_loss(test_pred_original, test_y_original, alpha=0.9))\n",
    "print(quantile_loss(test_pred_reduced, test_y_reduced, alpha=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "trainX_original = Variable(torch.from_numpy(train_data_original.astype(np.float32)))\n",
    "trainX_reduced = Variable(torch.from_numpy(train_data_reduced.astype(np.float32)))\n",
    "trainY = Variable(torch.from_numpy(train_target_reduced.astype(np.float32)))\n",
    "\n",
    "for alpha in alphas:\n",
    "    \n",
    "    regressor_original_dim = QuantileRegression(\n",
    "        input_size=25,\n",
    "        output_size=1,\n",
    "        hidden_size=40,\n",
    "        num_layers=1,\n",
    "        seq_length=12,\n",
    "        alpha = alpha\n",
    "    )\n",
    "\n",
    "    regressor_reduced_dim = QuantileRegression(\n",
    "        input_size=15,\n",
    "        output_size=1,\n",
    "        hidden_size=40,\n",
    "        num_layers=1,\n",
    "        seq_length=12,\n",
    "        alpha=alpha\n",
    "    )\n",
    "\n",
    "    losses = regressor_original_dim.train_model(\n",
    "        trainX = trainX_original,\n",
    "        trainY = trainY,\n",
    "        lr = 0.005,\n",
    "        epochs = 100,\n",
    "        sample_size = 50,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    losses = regressor_reduced_dim.train_model(\n",
    "        trainX = trainX_reduced,\n",
    "        trainY = trainY,\n",
    "        lr = 0.005,\n",
    "        epochs = 100,\n",
    "        sample_size = 50,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    regressor_original_dim.eval()\n",
    "    testYOriginalPredict = regressor_original_dim(testXOriginal)\n",
    "    test_pred_original = testYOriginalPredict.data.numpy()\n",
    "\n",
    "    regressor_reduced_dim.eval()\n",
    "    testYReducedPredict = regressor_reduced_dim(testXReduced)\n",
    "    test_pred_reduced = testYReducedPredict.data.numpy()\n",
    "\n",
    "    print('These are the losses before and after dimensionality reduction to 15 variables')\n",
    "    print('Before : ', quantile_loss(test_pred_original, test_y_original, alpha=alpha))\n",
    "    print('After : ', quantile_loss(test_pred_reduced, test_y_reduced, alpha=alpha))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
